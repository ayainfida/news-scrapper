{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from json import dumps, loads\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(base_url, categories, label='images'):\n",
    "    # create the following dir struct; outputs > base website > categories\n",
    "    base_dir = os.path.join('output', label, urlparse(base_url).netloc)\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    for category, _ in categories:\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        if not os.path.exists(category_dir):\n",
    "            os.makedirs(category_dir)\n",
    "\n",
    "    return base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_links(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    main_tag = soup.find('main', class_='main-content')\n",
    "    info_headers = main_tag.find_all('header', class_='info-header')\n",
    "    articles_links = []\n",
    "\n",
    "    for header in info_headers:\n",
    "        a_tag = header.find(class_='title').find('a')['href']\n",
    "        link = a_tag if a_tag.startswith('https') else f'https://www.foxnews.com{a_tag}'\n",
    "        articles_links.append(link)\n",
    "    \n",
    "    return articles_links\n",
    "\n",
    "def article_scrapper(url):\n",
    "    articles_links = get_articles_links(url)\n",
    "    data = []\n",
    "\n",
    "    def helper_scrapper(url):   \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        try:\n",
    "            time = datetime.strptime(soup.find('time').text.split('EDT')[-2].strip(), \"%B %d, %Y %I:%M%p\")\n",
    "            # time = soup.find('time').text.split('EDT')[-2].strip()\n",
    "            headline = soup.find('h1').text\n",
    "            content = soup.find('div', class_='article-body')\n",
    "            images = [(img['alt'], img['src']) for img in content.find_all('img')]\n",
    "\n",
    "            return headline, time, images\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    for url in articles_links:   \n",
    "        result = helper_scrapper(url)\n",
    "        if result is not None:\n",
    "            data.append(result)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_articles(data, n=10):\n",
    "    seen_headlines = set()\n",
    "    unique_data = []\n",
    "\n",
    "    for record in data:\n",
    "        headline = record[0]\n",
    "        if headline not in seen_headlines:\n",
    "            seen_headlines.add(headline)\n",
    "            unique_data.append(record)\n",
    "\n",
    "    return sorted(unique_data, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "def download_image(img_url, save_dir, img_name):\n",
    "    try:\n",
    "        if not img_url.startswith('data:'):\n",
    "            response = requests.get(img_url)\n",
    "            img_data = response.content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            width, height = img.size\n",
    "\n",
    "            # Only save images larger than 100x100 pixels\n",
    "            if width >= 100 and height >= 100:\n",
    "                with open(os.path.join(save_dir, img_name), 'wb') as img_file:\n",
    "                    img_file.write(img_data)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def download_images(category_url, save_dir, data):\n",
    "\n",
    "    with open(os.path.join(save_dir, 'labels.csv'), 'w') as f:\n",
    "        f.write('image number,alt,article_heading\\n')\n",
    "    \n",
    "    records = []\n",
    "\n",
    "    # parallising the downloads to make it faster\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "        headlines = []\n",
    "        for x, tuple in enumerate(data):\n",
    "            headline, _, images_list = tuple\n",
    "            for i, img in enumerate(images_list):\n",
    "                alt_txt, img_url = img\n",
    "                if alt_txt.startswith('Fox News'):\n",
    "                    continue\n",
    "                if img_url and not img_url.startswith('data:'):\n",
    "                    img_url = urljoin(category_url, img_url)\n",
    "                    combined_str = f\"{alt_txt}{headline}\".encode()\n",
    "                    img_name = f'image_{x+1}_{i+1}.jpg'\n",
    "                    records.append(f'{img_name},{alt_txt.replace(\",\", \"\")},{headline.replace(\",\", \"\")}\\n')\n",
    "                    futures.append(executor.submit(download_image, img_url, save_dir, img_name))\n",
    "        \n",
    "        with open(os.path.join(save_dir, 'labels.csv'), 'a') as f:\n",
    "            f.writelines(records)\n",
    "            \n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    (\"Crime\", \"https://www.foxnews.com/category/us/crime\"),\n",
    "    (\"Military\", \"https://www.foxnews.com/category/us/military\"),\n",
    "    (\"Education\", \"https://www.foxnews.com/category/us/education\"),\n",
    "    (\"Terror\", \"https://www.foxnews.com/category/us/terror\"),\n",
    "    (\"Immigration\", \"https://www.foxnews.com/category/us/immigration\"),\n",
    "    (\"Economy\", \"https://www.foxnews.com/category/us/economy\"),\n",
    "    (\"Personal Freedoms\", \"https://www.foxnews.com/category/us/personal-freedoms\"),\n",
    "    (\"Fox News Investigates\", \"https://www.foxnews.com/category/news-events/fox-news-investigates\"),\n",
    "    (\"Digital Originals\", \"https://www.foxnews.com/category/us/digital-originals\"),\n",
    "    (\"Executive\", \"https://www.foxnews.com/category/politics/executive\"),\n",
    "    (\"Senate\", \"https://www.foxnews.com/category/politics/senate\"),\n",
    "    (\"House\", \"https://www.foxnews.com/category/politics/house-of-representatives\"),\n",
    "    (\"Judiciary\", \"https://www.foxnews.com/category/politics/judiciary\"),\n",
    "    (\"Foreign Policy\", \"https://www.foxnews.com/category/politics/foreign-policy\"),\n",
    "    (\"Polls\", \"https://www.foxnews.com/official-polls\"),\n",
    "    (\"Elections\", \"https://www.foxnews.com/elections\"),\n",
    "    (\"U.N.\", \"https://www.foxnews.com/category/world/united-nations\"),\n",
    "    (\"Conflicts\", \"https://www.foxnews.com/category/world/conflicts\"),\n",
    "    (\"Terrorism\", \"https://www.foxnews.com/category/world/terrorism\"),\n",
    "    (\"Disasters\", \"https://www.foxnews.com/category/world/disasters\"),\n",
    "    (\"Global Economy\", \"https://www.foxnews.com/category/world/global-economy\"),\n",
    "    (\"Environment\", \"https://www.foxnews.com/category/world/environment\"),\n",
    "    (\"Religion\", \"https://www.foxnews.com/category/world/religion\"),\n",
    "    (\"Scandals\", \"https://www.foxnews.com/category/world/scandals\"),\n",
    "    (\"FOX Nation Coverage\", \"https://www.foxnews.com/shows/fox-nation\"),\n",
    "    (\"Entertainment\", \"https://www.foxnews.com/entertainment\"),\n",
    "    (\"Celebrity News\", \"https://www.foxnews.com/category/entertainment/celebrity-news\"),\n",
    "    (\"Movies\", \"https://www.foxnews.com/category/entertainment/movies\"),\n",
    "    (\"TV News\", \"https://www.foxnews.com/category/entertainment/tv\"),\n",
    "    (\"Music News\", \"https://www.foxnews.com/category/entertainment/music\"),\n",
    "    (\"Style News\", \"https://www.foxnews.com/category/entertainment/style\"),\n",
    "    (\"Entertainment Video\", \"https://www.foxnews.com/video/topics/entertainment\"),\n",
    "    (\"Sports\", \"https://www.foxnews.com/sports\"),\n",
    "    (\"NFL\", \"https://www.foxnews.com/category/sports/nfl\"),\n",
    "    (\"College Football\", \"https://www.foxnews.com/category/sports/ncaa-fb\"),\n",
    "    (\"MLB\", \"https://www.foxnews.com/category/sports/mlb\"),\n",
    "    (\"NBA\", \"https://www.foxnews.com/category/sports/nba\"),\n",
    "    (\"NHL\", \"https://www.foxnews.com/category/sports/nhl\"),\n",
    "    (\"Golf\", \"https://www.foxnews.com/category/sports/golf\"),\n",
    "    (\"Tennis\", \"https://www.foxnews.com/category/sports/tennis\"),\n",
    "    (\"Soccer\", \"https://www.foxnews.com/category/sports/soccer\"),\n",
    "    (\"UFC\", \"https://www.foxnews.com/category/sports/ufc\"),\n",
    "    (\"WWE\", \"https://www.foxnews.com/category/organization/wwe\"),\n",
    "    (\"Lifestyle\", \"https://www.foxnews.com/lifestyle\"),\n",
    "    (\"Health\", \"https://www.foxnews.com/health\"),\n",
    "    (\"Food & Drink\", \"https://www.foxnews.com/food-drink\"),\n",
    "    (\"Auto\", \"https://www.foxnews.com/category/auto\"),\n",
    "    (\"Travel & Outdoors\", \"https://www.foxnews.com/travel\"),\n",
    "    (\"Real Estate\", \"https://www.foxnews.com/category/real-estate\"),\n",
    "    (\"House & Home\", \"https://www.foxnews.com/category/house-and-home\"),\n",
    "    (\"Style & Beauty\", \"https://www.foxnews.com/category/style-and-beauty\"),\n",
    "    (\"Family\", \"https://www.foxnews.com/family\"),\n",
    "    (\"Faith\", \"https://www.foxnews.com/category/faith-values/faith\"),\n",
    "    (\"Science & Tech\", \"https://www.foxnews.com/tech\"),\n",
    "    (\"Air & Space\", \"https://www.foxnews.com/category/science/air-and-space\"),\n",
    "    (\"Security\", \"https://www.foxnews.com/category/tech/topics/security\"),\n",
    "    (\"Innovation\", \"https://www.foxnews.com/category/tech/topics/innovation\"),\n",
    "    (\"Planet Earth\", \"https://www.foxnews.com/category/science/planet-earth\"),\n",
    "    (\"Wild Nature\", \"https://www.foxnews.com/category/science/wild-nature\"),\n",
    "    (\"Video Games\", \"https://www.foxnews.com/category/tech/topics/video-games\"),\n",
    "    (\"Military Tech\", \"https://www.foxnews.com/category/tech/topics/military-tech\"),\n",
    "    (\"FOX News Shows\", \"https://www.foxnews.com/shows\"),\n",
    "    (\"Programming Schedule\", \"https://www.foxnews.com/fnctv\"),\n",
    "    (\"On Air Personalities\", \"https://www.foxnews.com/person/personalities\"),\n",
    "    (\"Full Episodes\", \"https://www.foxnews.com/video/shows\"),\n",
    "    (\"Show Clips\", \"https://www.foxnews.com/video/topics/v-most-recent-episodes\"),\n",
    "    (\"News Clips\", \"https://www.foxnews.com/video/topics/latest-news-video\"),\n",
    "    (\"Apps & Products\", \"https://www.foxnews.com/apps-products\"),\n",
    "    (\"FOX News Go\", \"https://www.foxnews.com/go\"),\n",
    "    (\"FOX Nation\", \"https://www.foxnews.com/shows/fox-nation\"),\n",
    "    (\"Podcasts\", \"https://radio.foxnews.com/podcast/\"),\n",
    "]\n",
    "\n",
    "\n",
    "base_url = 'https://www.foxnews.com/'\n",
    "\n",
    "base_dir = create_directories(base_url, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images for every category: 100%|██████████| 71/71 [05:29<00:00,  4.64s/it]\n"
     ]
    }
   ],
   "source": [
    "for category, category_url in tqdm(categories, desc='Downloading images for every category'):\n",
    "    try:\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        data = article_scrapper(f'{base_url}{category}')\n",
    "        download_images(category_url, category_dir, get_latest_articles(data))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for cat in os.listdir('output/images/www.foxnews.com'):\n",
    "    if len(os.listdir(f'output/images/www.foxnews.com/{cat}')) == 1:\n",
    "        shutil.rmtree(f'output/images/www.foxnews.com/{cat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labels.csv')\n",
    "n, _ = df.shape\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        pairs.append((list(df.iloc[i]), list(df.iloc[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(base_dir):\n",
    "    for category in os.listdir(base_dir):\n",
    "        try:\n",
    "            df = pd.read_csv(f'{base_dir}{category}/labels.csv')\n",
    "            n, _ = df.shape\n",
    "\n",
    "            pairs = []\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(i + 1, n):\n",
    "                    article_1 = int(re.search(r'\\d+(?=_|$)',list(df.iloc[i])[0]).group())\n",
    "                    article_2 = int(re.search(r'\\d+(?=_|$)',list(df.iloc[j])[0]).group())\n",
    "                    if article_1 != article_2:\n",
    "                        pairs.append((list(df.iloc[i]), list(df.iloc[j])))\n",
    "\n",
    "            with open(f'{base_dir.split(\"/\")[2]}_pairs_{category}.csv', 'w') as f:\n",
    "                for i, pair in enumerate(pairs):\n",
    "                    p1, p2 = pair\n",
    "                    img1, alt1, headline1 = p1\n",
    "                    img2, alt2, headline2 = p2\n",
    "                    f.write(f'{i+1},{headline1},{headline2}\\n')\n",
    "                    f.write(f',https://raw.githubusercontent.com/ayainfida/news-scrapper/main/output/images/www.foxnews.com/{urllib.parse.quote(category)}/{img1},https://raw.githubusercontent.com/ayainfida/news-scrapper/main/output/images/www.foxnews.com/{urllib.parse.quote(category)}/{img2}\\n')\n",
    "                    f.write(f',{alt1},{alt2}\\n')\n",
    "\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "create_file('output/images/www.foxnews.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pairs = []\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.startswith('www.foxnews.com_pairs'):\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            num_pairs.append((int(list(df.iloc[-3])[0]), file))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(460, 'www.foxnews.com_pairs_Golf.csv'),\n",
       " (607, 'www.foxnews.com_pairs_Immigration.csv'),\n",
       " (621, 'www.foxnews.com_pairs_Education.csv'),\n",
       " (637, 'www.foxnews.com_pairs_Executive.csv'),\n",
       " (663, 'www.foxnews.com_pairs_Economy.csv'),\n",
       " (664, 'www.foxnews.com_pairs_Disasters.csv'),\n",
       " (722, 'www.foxnews.com_pairs_Environment.csv'),\n",
       " (785, 'www.foxnews.com_pairs_Crime.csv'),\n",
       " (906, 'www.foxnews.com_pairs_House.csv'),\n",
       " (990, 'www.foxnews.com_pairs_Lifestyle.csv'),\n",
       " (1121, 'www.foxnews.com_pairs_Faith.csv')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_array = sorted(num_pairs, key=lambda x: x[0])\n",
    "sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "cat = []\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.startswith('www.foxnews.com') and file.endswith('.csv'):\n",
    "        cat.append(file.replace('.csv', '').split('_')[-1])\n",
    "\n",
    "for dir in os.listdir('output/images/www.foxnews.com'):\n",
    "    if dir not in cat:\n",
    "        shutil.rmtree(f'output/images/www.foxnews.com/{dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
