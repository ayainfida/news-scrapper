{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvL2SncEoye-",
        "outputId": "79d1e483-0168-4600-9131-fddad5c42d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2024.8.30)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install deep_translator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "from urllib.parse import urljoin, urlparse\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "from deep_translator import GoogleTranslator\n",
        "from datetime import datetime\n",
        "import urllib.parse\n",
        "from json import dumps, loads\n",
        "from shutil import copy2"
      ],
      "metadata": {
        "id": "cWUy8-w5pALv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/research-similarity/Scraping')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUgljkLGpCGe",
        "outputId": "1e52071e-5c9d-4774-e887-37b30f08ece8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text):\n",
        "    try:\n",
        "        return GoogleTranslator(source='es', target='en').translate(text=text).replace(',', '').replace('\\n', '')\n",
        "    except:\n",
        "        return text\n",
        "\n",
        "def create_directories(base_url, categories, label='images'):\n",
        "    # create the following dir struct; outputs > base website > categories\n",
        "    base_dir = os.path.join('output', label, urlparse(base_url).netloc)\n",
        "    if not os.path.exists(base_dir):\n",
        "        os.makedirs(base_dir)\n",
        "\n",
        "    for category, _ in categories:\n",
        "        category_dir = os.path.join(base_dir, category)\n",
        "        if not os.path.exists(category_dir):\n",
        "            os.makedirs(category_dir)\n",
        "\n",
        "    return base_dir"
      ],
      "metadata": {
        "id": "oIxJI7w0qDZi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_articles_links(category):\n",
        "    with open(f'../links/{category}.json', 'r') as f:\n",
        "        return loads(f.read())\n",
        "\n",
        "def article_scrapper(category):\n",
        "    articles_links = get_articles_links(category)\n",
        "    data = []\n",
        "\n",
        "    def helper_scrapper(url):\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'lxml')\n",
        "        try:\n",
        "            headline = translate(soup.find('h1').text)\n",
        "            images = []\n",
        "            datetime_str = soup.find('span', class_='sharebar-article-date').text[:-4].replace(\".\", \"\")\n",
        "            time = datetime.strptime(datetime_str, \"%d %b, %Y %I:%M %p\")\n",
        "\n",
        "            for img in soup.find('div', class_='body-article').find_all('img'):\n",
        "                img_alt = translate(img.get('alt', ''))  # Safely get the 'alt' attribute\n",
        "                img_src = img.get('src', '')[:img.get('src', '').find('&smart')]  # Safely get the 'src' attribute\n",
        "\n",
        "                if (img_alt, img_src) not in images:\n",
        "                    images.append((img_alt, img_src))\n",
        "\n",
        "            return headline, time, images\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    for url in articles_links:\n",
        "        result = helper_scrapper(url)\n",
        "        if result is not None:\n",
        "            data.append(result)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "AqIot93DtOsB"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_latest_articles(data, n=10):\n",
        "    seen_headlines = set()\n",
        "    unique_data = []\n",
        "\n",
        "    for record in data:\n",
        "        headline = record[0]\n",
        "        if headline not in seen_headlines:\n",
        "            seen_headlines.add(headline)\n",
        "            unique_data.append(record)\n",
        "\n",
        "    return sorted(unique_data, key=lambda x: x[1], reverse=True)[:n]\n",
        "\n",
        "def download_image(img_url, save_dir, img_name):\n",
        "    try:\n",
        "        if not img_url.startswith('data:'):\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            }\n",
        "            response = requests.get(img_url, headers=headers)\n",
        "            img_data = response.content\n",
        "            img = Image.open(BytesIO(img_data))\n",
        "            width, height = img.size\n",
        "\n",
        "            # Only save images larger than 100x100 pixels\n",
        "            if width >= 100 and height >= 100:\n",
        "                with open(os.path.join(save_dir, img_name), 'wb') as img_file:\n",
        "                    img_file.write(img_data)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def download_images(category_url, save_dir, data):\n",
        "\n",
        "    with open(os.path.join(save_dir, 'labels.csv'), 'w') as f:\n",
        "        f.write('image number,alt,article_heading\\n')\n",
        "\n",
        "    records = []\n",
        "\n",
        "    # parallising the downloads to make it faster\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "        headlines = []\n",
        "        for x, tuple in enumerate(data):\n",
        "            headline, _, images_list = tuple\n",
        "            for i, img in enumerate(images_list):\n",
        "                alt_txt, img_url = img\n",
        "                if img_url and not img_url.startswith('data:'):\n",
        "                    img_url = urljoin(category_url, img_url)\n",
        "                    combined_str = f\"{alt_txt}{headline}\".encode()\n",
        "                    img_name = f'image_{x+1}_{i+1}.jpg'\n",
        "                    records.append(f'{img_name},{alt_txt.replace(\",\", \"\")},{headline.replace(\",\", \"\")}\\n')\n",
        "                    futures.append(executor.submit(download_image, img_url, save_dir, img_name))\n",
        "\n",
        "        with open(os.path.join(save_dir, 'labels.csv'), 'a') as f:\n",
        "            f.writelines(records)\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            future.result()"
      ],
      "metadata": {
        "id": "bUlFuVV4ugji"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\n",
        "    ('Fintech World', 'https://www.infobae.com/tag/mundo-fintech/'),\n",
        "    ('Techno Cars and Mobility', 'https://www.infobae.com/tag/tecno-autos-y-movilidad/'),\n",
        "    ('Entertainment', 'https://www.infobae.com/entretenimiento/'),\n",
        "    ('Health', 'https://www.infobae.com/salud/'),\n",
        "    ('Russia Ukraine War', 'https://www.infobae.com/tag/guerra-rusia-ucrania/'),\n",
        "    ('Crime and Justice', 'https://www.infobae.com/sociedad/policiales/'),\n",
        "    ('Society', 'https://www.infobae.com/sociedad/'),\n",
        "    ('Policy', 'https://www.infobae.com/politica/'),\n",
        "    ('Music', 'https://www.infobae.com/tag/musica/'),\n",
        "    ('Arts', 'https://www.infobae.com/tag/arte/'),\n",
        "    ('Cinema', 'https://www.infobae.com/tag/cine/'),\n",
        "    ('Series', 'https://www.infobae.com/tag/series/'),\n",
        "    ('Education', 'https://www.infobae.com/educacion/'),\n",
        "    ('Tourism', 'https://www.infobae.com/turismo/'),\n",
        "]\n",
        "\n",
        "base_url = 'https://www.infobae.com/'\n",
        "\n",
        "base_dir = create_directories(base_url, categories)"
      ],
      "metadata": {
        "id": "o0XAFSRcu_u9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category, category_url in tqdm(categories, desc='Downloading images for every category'):\n",
        "    try:\n",
        "        category_dir = os.path.join(base_dir, category)\n",
        "        data = article_scrapper(category)\n",
        "        download_images(category_url, category_dir, get_latest_articles(data))\n",
        "    except:\n",
        "        print(category)\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UopH8c3k83M3",
        "outputId": "7e6b74f7-e948-4061-a1bf-ca7b85f26e07"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading images for every category: 100%|██████████| 14/14 [13:26<00:00, 57.62s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_file(base_dir):\n",
        "    for category in os.listdir(base_dir):\n",
        "        try:\n",
        "            df = pd.read_csv(f'{base_dir}{category}/labels.csv')\n",
        "            n, _ = df.shape\n",
        "\n",
        "            pairs = []\n",
        "\n",
        "            for i in range(n):\n",
        "                for j in range(i + 1, n):\n",
        "                    article_1 = int(re.search(r'\\d+(?=_|$)',list(df.iloc[i])[0]).group())\n",
        "                    article_2 = int(re.search(r'\\d+(?=_|$)',list(df.iloc[j])[0]).group())\n",
        "                    if article_1 != article_2:\n",
        "                        pairs.append((list(df.iloc[i]), list(df.iloc[j])))\n",
        "\n",
        "            with open(f'{base_dir.split(\"/\")[2]}_pairs_{category}.csv', 'w') as f:\n",
        "                for i, pair in enumerate(pairs):\n",
        "                    p1, p2 = pair\n",
        "                    img1, alt1, headline1 = p1\n",
        "                    img2, alt2, headline2 = p2\n",
        "                    f.write(f'{i+1},{headline1},{headline2}\\n')\n",
        "                    f.write(f',https://raw.githubusercontent.com/ayainfida/news-scrapper/main/output/images/www.infobae.com/{urllib.parse.quote(category)}/{img1},https://raw.githubusercontent.com/ayainfida/news-scrapper/main/output/images/www.infobae.com/{urllib.parse.quote(category)}/{img2}\\n')\n",
        "                    f.write(f',{alt1},{alt2}\\n')\n",
        "\n",
        "        except:\n",
        "            continue"
      ],
      "metadata": {
        "id": "-BM39E9T9MIz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in os.listdir('output/images/www.infobae.com/'):\n",
        "    df = pd.read_csv(f'output/images/www.infobae.com/{category}/labels.csv')\n",
        "    n, _ = df.shape\n",
        "\n",
        "    if n + 1 != len(os.listdir(f'output/images/www.infobae.com/{category}')):\n",
        "        print(category,n+1, len(os.listdir(f'output/images/www.infobae.com/{category}')))"
      ],
      "metadata": {
        "id": "qpuTvSvX9DjJ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_file('output/images/www.infobae.com/')"
      ],
      "metadata": {
        "id": "h-i3lawRBnLA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_pairs = []\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.startswith('www.infobae.com_pairs'):\n",
        "        try:\n",
        "            df = pd.read_csv(file)\n",
        "            num_pairs.append((int(list(df.iloc[-3])[0]), file))\n",
        "        except:\n",
        "            continue"
      ],
      "metadata": {
        "id": "BH6-0_C4BqM4"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_array = sorted(num_pairs, key=lambda x: x[0])\n",
        "sorted_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8QNiD1BBsgt",
        "outputId": "5e73272a-bd4c-4181-aa8a-c7793351cac5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(85, 'www.infobae.com_pairs_Cinema.csv'),\n",
              " (210, 'www.infobae.com_pairs_Crime and Justice.csv'),\n",
              " (258, 'www.infobae.com_pairs_Fintech World.csv'),\n",
              " (279, 'www.infobae.com_pairs_Policy.csv'),\n",
              " (280, 'www.infobae.com_pairs_Education.csv'),\n",
              " (375, 'www.infobae.com_pairs_Techno Cars and Mobility.csv'),\n",
              " (376, 'www.infobae.com_pairs_Russia Ukraine War.csv'),\n",
              " (397, 'www.infobae.com_pairs_Society.csv'),\n",
              " (577, 'www.infobae.com_pairs_Series.csv'),\n",
              " (582, 'www.infobae.com_pairs_Arts.csv'),\n",
              " (639, 'www.infobae.com_pairs_Health.csv'),\n",
              " (993, 'www.infobae.com_pairs_Entertainment.csv'),\n",
              " (2463, 'www.infobae.com_pairs_Tourism.csv')]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    }
  ]
}