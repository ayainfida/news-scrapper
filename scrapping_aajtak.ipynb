{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lMQRoR2Svbr"
      },
      "outputs": [],
      "source": [
        "!pip install deep_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf-6A6szS3D2"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "from urllib.parse import urljoin, urlparse\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "from deep_translator import GoogleTranslator\n",
        "from datetime import datetime\n",
        "import urllib.parse\n",
        "from json import dumps, loads\n",
        "from shutil import copy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Khh7HzSxsf",
        "outputId": "8fd245a8-547c-4a14-c9b6-4a93b3b73857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/research-similarity/Scraping')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "af6jVaMUTAz7"
      },
      "outputs": [],
      "source": [
        "def translate(text):\n",
        "    try:\n",
        "        return GoogleTranslator(source='hi', target='en').translate(text=text).replace(',', '').replace('\\n', '')\n",
        "    except:\n",
        "        return text\n",
        "\n",
        "def create_directories(base_url, categories, label='images'):\n",
        "    # create the following dir struct; outputs > base website > categories\n",
        "    base_dir = os.path.join('output', label, urlparse(base_url).netloc)\n",
        "    if not os.path.exists(base_dir):\n",
        "        os.makedirs(base_dir)\n",
        "\n",
        "    for category, _ in categories:\n",
        "        category_dir = os.path.join(base_dir, category)\n",
        "        if not os.path.exists(category_dir):\n",
        "            os.makedirs(category_dir)\n",
        "\n",
        "    return base_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SyzN4hKNVdZ4"
      },
      "outputs": [],
      "source": [
        "def get_articles_links(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "    main_content = soup.find('div', class_='section-listing-LHS')\n",
        "    articles_links = []\n",
        "\n",
        "    for a_tag in main_content.find_all('a'):\n",
        "        link = a_tag['href']\n",
        "        if link.startswith('https') and 'video' not in link.split('/') and 'photo' not in link.split('/') and link not in articles_links:\n",
        "            articles_links.append(link)\n",
        "\n",
        "    return articles_links\n",
        "\n",
        "def article_scrapper(url):\n",
        "    articles_links = get_articles_links(url)\n",
        "    data = []\n",
        "\n",
        "    def helper_scrapper(url):\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'lxml')\n",
        "        try:\n",
        "            headline = translate(soup.find('h1').text)\n",
        "            featured_img = soup.find('div', class_='main-img').find('img')\n",
        "            images = [(featured_img.get('alt'), translate(featured_img.get('data-src')))]\n",
        "            datetime_str = translate(soup.find('div', class_=\"brand-detial-main\").find_all('li')[-1].text).replace('(Updated ', '').replace(' IST)', '')\n",
        "            time = datetime.strptime(datetime_str, \"%B %d %Y %I:%M %p\")\n",
        "\n",
        "            return headline, time, images\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    for url in articles_links:\n",
        "        result = helper_scrapper(url)\n",
        "        if result is not None:\n",
        "            data.append(result)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keWUhCRRLROm"
      },
      "outputs": [],
      "source": [
        "def get_latest_articles(data, n=10):\n",
        "    seen_headlines = set()\n",
        "    unique_data = []\n",
        "\n",
        "    for record in data:\n",
        "        headline = record[0]\n",
        "        if headline not in seen_headlines:\n",
        "            seen_headlines.add(headline)\n",
        "            unique_data.append(record)\n",
        "\n",
        "    return sorted(unique_data, key=lambda x: x[1], reverse=True)[:n]\n",
        "\n",
        "def download_image(img_url, save_dir, img_name):\n",
        "    try:\n",
        "        if not img_url.startswith('data:'):\n",
        "            response = requests.get(img_url)\n",
        "            img_data = response.content\n",
        "            img = Image.open(BytesIO(img_data))\n",
        "            width, height = img.size\n",
        "\n",
        "            # Only save images larger than 100x100 pixels\n",
        "            if width >= 100 and height >= 100:\n",
        "                with open(os.path.join(save_dir, img_name), 'wb') as img_file:\n",
        "                    img_file.write(img_data)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def download_images(category_url, save_dir, data):\n",
        "\n",
        "    with open(os.path.join(save_dir, 'labels.csv'), 'w') as f:\n",
        "        f.write('image number,alt,article_heading\\n')\n",
        "\n",
        "    records = []\n",
        "\n",
        "    # parallising the downloads to make it faster\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "        headlines = []\n",
        "        for x, tuple in enumerate(data):\n",
        "            headline, _, images_list = tuple\n",
        "            for i, img in enumerate(images_list):\n",
        "                alt_txt, img_url = img\n",
        "                if img_url and not img_url.startswith('data:'):\n",
        "                    img_url = urljoin(category_url, img_url)\n",
        "                    combined_str = f\"{alt_txt}{headline}\".encode()\n",
        "                    img_name = f'image_{x+1}_{i+1}.jpg'\n",
        "                    records.append(f'{img_name},{alt_txt.replace(\",\", \"\")},{headline.replace(\",\", \"\")}\\n')\n",
        "                    futures.append(executor.submit(download_image, img_url, save_dir, img_name))\n",
        "\n",
        "        with open(os.path.join(save_dir, 'labels.csv'), 'a') as f:\n",
        "            f.writelines(records)\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            future.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2EVQ0ZjALROq"
      },
      "outputs": [],
      "source": [
        "categories = [\n",
        "    ('Bollywood', 'https://www.aajtak.in/entertainment/bollywood-news'),\n",
        "    ('Relationship', 'https://www.aajtak.in/lifestyle/relationship'),\n",
        "    ('Lifestyle News', 'https://www.aajtak.in/lifestyle/news'),\n",
        "    ('Fashion', 'https://www.aajtak.in/lifestyle/fashion'),\n",
        "    ('Tour and Tourism', 'https://www.aajtak.in/lifestyle/tourism'),\n",
        "    ('Food', 'https://www.aajtak.in/lifestyle/food'),\n",
        "    ('Movie Reviews', 'https://www.aajtak.in/entertainment/film-review'),\n",
        "    ('Hollywood', 'https://www.aajtak.in/entertainment/hollywood'),\n",
        "    ('Festivals', 'https://www.aajtak.in/religion/festivals'),\n",
        "    ('Spirtuality', 'https://www.aajtak.in/religion/spirituality'),\n",
        "    ('Religion', 'https://www.aajtak.in/religion/news'),\n",
        "    ('Tech News', 'https://www.aajtak.in/technology/tech-news'),\n",
        "    ('Science', 'https://www.aajtak.in/science'),\n",
        "    ('Crime', 'https://www.aajtak.in/crime/news'),\n",
        "    ('Police and Intelligence', 'https://www.aajtak.in/crime/police-and-intelligence'),\n",
        "    ('Cyber Crime', 'https://www.aajtak.in/crime/cyber-crime'),\n",
        "    ('Cricket', 'https://www.aajtak.in/sports/cricket'),\n",
        "    ('Football', 'https://www.aajtak.in/sports/football'),\n",
        "    ('Tennis', 'https://www.aajtak.in/sports/tennis')\n",
        "]\n",
        "\n",
        "base_url = 'https://www.aajtak.in/'\n",
        "\n",
        "base_dir = create_directories(base_url, categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lNmgK_h8LROr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de9a971-9752-4cb5-c66c-78af0550fef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading images for every category: 100%|██████████| 19/19 [05:24<00:00, 17.10s/it]\n"
          ]
        }
      ],
      "source": [
        "for category, category_url in tqdm(categories, desc='Downloading images for every category'):\n",
        "    category_dir = os.path.join(base_dir, category)\n",
        "    try:\n",
        "        data = article_scrapper(category_url)\n",
        "        download_images(category_url, category_dir, get_latest_articles(data))\n",
        "    except:\n",
        "        print(category)\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0QJt-NMgLROs"
      },
      "outputs": [],
      "source": [
        "def create_file(base_dir):\n",
        "    for category in os.listdir(base_dir):\n",
        "        try:\n",
        "            df = pd.read_csv(f'{base_dir}{category}/labels.csv')\n",
        "            n, _ = df.shape\n",
        "\n",
        "            pairs = []\n",
        "\n",
        "            for i in range(n):\n",
        "                for j in range(i + 1, n):\n",
        "                    article_1 = int(re.search(r'\\d+(?=_|$)',list(df.iloc[i])[0]).group())\n",
        "                    article_2 = int(re.search(r'\\d+(?=_|$)',list(df.iloc[j])[0]).group())\n",
        "                    if article_1 != article_2:\n",
        "                        pairs.append((list(df.iloc[i]), list(df.iloc[j])))\n",
        "\n",
        "            with open(f'{base_dir.split(\"/\")[2]}_pairs_{category}.csv', 'w') as f:\n",
        "                for i, pair in enumerate(pairs):\n",
        "                    p1, p2 = pair\n",
        "                    img1, alt1, headline1 = p1\n",
        "                    img2, alt2, headline2 = p2\n",
        "                    f.write(f'{i+1},{headline1},{headline2}\\n')\n",
        "                    f.write(f',https://raw.githubusercontent.com/ayainfida/news-scrapper/main/output/images/www.aajtak.in/{urllib.parse.quote(category)}/{img1},https://raw.githubusercontent.com/ayainfida/news-scrapper/main/output/images/www.aajtak.in/{urllib.parse.quote(category)}/{img2}\\n')\n",
        "                    f.write(f',{alt1},{alt2}\\n')\n",
        "\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kNlQsKrALROs"
      },
      "outputs": [],
      "source": [
        "create_file('output/images/www.aajtak.in/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "for cat in os.listdir('output/images/www.aajtak.in/'):\n",
        "    try:\n",
        "        df = pd.read_csv(f'output/images/www.aajtak.in/{cat}/labels.csv')\n",
        "        n, _ = df.shape\n",
        "        if n + 1 == len(os.listdir(f'output/images/www.aajtak.in/{cat}')) and n == 10:\n",
        "            print(cat, n, len(os.listdir(f'output/images/www.aajtak.in/{cat}'))-1)\n",
        "        else:\n",
        "            shutil.rmtree(f'output/images/www.aajtak.in/{cat}')\n",
        "    except:\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNICJH4gSxZO",
        "outputId": "66e42ea2-495a-4a80-a46e-9fe730b1ede9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relationship 10 10\n",
            "Lifestyle News 10 10\n",
            "Fashion 10 10\n",
            "Tour and Tourism 10 10\n",
            "Movie Reviews 10 10\n",
            "Festivals 10 10\n",
            "Police and Intelligence 10 10\n",
            "Cricket 10 10\n",
            "Tennis 10 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jpqiYecRLROt"
      },
      "outputs": [],
      "source": [
        "num_pairs = []\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.startswith('www.aajtak.in_pairs'):\n",
        "        try:\n",
        "            df = pd.read_csv(file)\n",
        "            num_pairs.append((int(list(df.iloc[-3])[0]), file))\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0mrXDw77LROt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbe26e1-cebb-4c1a-9751-f66196e4306b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(45, 'www.aajtak.in_pairs_Relationship.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Lifestyle News.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Fashion.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Tour and Tourism.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Movie Reviews.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Festivals.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Police and Intelligence.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Cricket.csv'),\n",
              " (45, 'www.aajtak.in_pairs_Tennis.csv')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "sorted_array = sorted(num_pairs, key=lambda x: x[0])\n",
        "sorted_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yTvwVApyLROu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e6698d-00a7-47fd-b47d-0242658bb8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(45, 'www.aajtak.in_pairs_Festivals.csv'), (45, 'www.aajtak.in_pairs_Cricket.csv'), (45, 'www.aajtak.in_pairs_Movie Reviews.csv'), (45, 'www.aajtak.in_pairs_Relationship.csv'), (45, 'www.aajtak.in_pairs_Tour and Tourism.csv'), (45, 'www.aajtak.in_pairs_Lifestyle News.csv'), (45, 'www.aajtak.in_pairs_Police and Intelligence.csv'), (45, 'www.aajtak.in_pairs_Tennis.csv'), (45, 'www.aajtak.in_pairs_Fashion.csv')]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.shuffle(sorted_array)\n",
        "print(sorted_array)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}